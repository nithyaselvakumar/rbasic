seq(4,4)
mapply(rep, 1:4, 1:4)
mapply(rep, 1:3, 1:3)
tapply(mpg, list(cyl, gear), sum)
data(mtcars)
tapply(mpg, list(cyl, gear), sum)
head(mtcars)
tapply(mpg, list(mtcars$cyl, mtcars$gear), sum)
tapply(mtcars$mpg, list(mtcars$cyl, mtcars$gear), sum)
?mtcars
tapply(mtcars$mpg, list(mtcars$cyl, mtcars$gear), mean)
fileurl = 'http://data.tainan.gov.tw/dataset/e70e2580-b45b-457f-8715-d1d0846434ac/resource/4a9a150a-e79a-4ae0-bcec-abd3e619f6a3/download/landmark2.csv'
download.file(fileurl, destfile = 'landmark2.csv', method = "curl")
read.data = read.table(header= TRUE, file='landmark2.csv', sep=',')
read.data
View(read.data)
View(read.data)
getwd()
read.data = read.table(header= TRUE, file='landmark2.csv', sep=',', encoding = 'UTF-8')
View(read.data)
read.data2 = read.table(header= TRUE, file='landmark2.csv', sep=',', encoding = 'UTF-8')
View(read.data2)
read.data3 = read.table(header= TRUE, file='landmark2.csv', sep=',', encoding = 'UTF-8')
View(read.data3)
head(read.data3)
read.data2 = read.csv(header= TRUE, file='landmark2.csv',encoding = 'UTF-8')
2330.data = read.xlsx(header = TRUE, file= '2330.xlsx')
2330.data = read.xlsx(header = TRUE, file= '2330.xlsx', sheetIndex = 1)
test = read.xlsx(header = TRUE, file= '2330.xlsx', sheetIndex = 1)
test = read.xlsx(header = TRUE, file= '2330_1.xlsx', sheetIndex = 1)
library(xlsx)
install.packages("xlsx")
library(xlsx)
library(xlsx)
library(rJava)
install.packages("rJava")
library(rJava)
library(xlsx)
install.packages("jsonlite")
library(jsonlite)
jsondata = fromJSON("http://goristock.appspot.com/API/stock?q=2330")
install.packages('httr')
jsondata = fromJSON("http://goristock.appspot.com/API/stock?q=2330")
jsondata = fromJSON("https://api.github.com/useres/ywchiu/repo")
jsondata = fromJSON("https://api.github.com/users/ywchiu/repo")
jsondata = fromJSON("https://api.github.com/users/ywchiu/repos")
jsondata
if(!file.exisits("data")){
file.create("data")
}
if(!file.exists("data")){
file.create("data")
}
library(xlsx)
library(XML)
fileurl = "http://data.ntpc.gov.tw/NTPC/od/data/api/IMC14?$format=xml&$top=3"
doc = xmlTreeParse(fileurl)
doc
doc$childeren$data
doc$children$data
doc$children$data
doc$children
doc
con = url("http://travel.rakuten.com/hotel/Japan-Hokkaido-Noboribetsu-Noboribetsu_Onsen_Noboribetsu_Grand_Hotel/39175/")
htmlcode = readLines(con)
close(con)
htmlcode
library(XML)
url = 'http://travel.rakuten.com/hotel/Japan-Hokkaido-Noboribetsu-Noboribetsu_Onsen_Noboribetsu_Grand_Hotel/39175/'
html = htmlTreeParse(url, useInternLNodes=T)
xpathSApply(html, "//title", xmlValue)
html = htmlTreeParse(url, useInternalNodes=T)
xpathSApply(html, "//title", xmlValue)
library(httr)
url = 'http://travel.rakuten.com/hotel/Japan-Hokkaido-Noboribetsu-Noboribetsu_Onsen_Noboribetsu_Grand_Hotel/39175/'
htmlPage = GET(url)
content = content(htmlPage, as="text")
html = htmlParse(content, asText=TRUE)
xpathSApply(html, "//title", xmlValue)
install.packages("RMySQL")
stock_data[order(stock_data$Open, stock_data$Close),]
df1 = data.frame(id = 1:3, x= rep(1,3))
df1
df2 = data.frame(id = 1:3, x= rnorm(3))
df1
fg2
df1
df2
arrange(join(df1,df2), id)
arrange(join(df1,df2), id)
library(plyr)
arrange(join(df1,df2), id)
df1 = data.frame(id = 1:3, x= rep(1,3))
df2 = data.frame(id = 1:3, y= rnorm(3))
arrange(join(df1,df2), id)
list(df1,df2)
a = list(df1,df2)
joinAll(a)
join_all(a)
merge(df1,df1,by.x="id", by.y"id", all=TRUE)
merge(df1,df2,by.x="id", by.y"id", all=TRUE)
merge(df1,df2, by.x="id", by.y="id", all=TRUE)
gsub("_", "", "123_456" )
gsub("_", "", "123_456_789" )
ssub("_", "", "123_456_789" )
sub("_", "", "123_456_789" )
v = c("Brian", "Brain", "Cat")
grep("B", v)
talble(grep("B",v))
table(grep("B",v))
table(grepl("B",v))
library(stringr)
nchar("hello world")
substr("hello world", 1,8)
paste("Hello", "World")
paste0("Hello", "World")
str_trim("Hello   ")
x <- c("abc", "def", "cba a", "aa")
m <- regexpr("a+", x, perl=TRUE)
regmatches(x, m)
sub("(a+)", "z\\1z", c("abc", "def", "cba a", "aa"), perl=TRUE)
gsub("(a+)", "z\\1z", c("abc", "def", "cba a", "aa"), perl=TRUE)
emails = c("larry@gmail.com", "larry-sally@sally.com", "larry@sally.larry.com")
regex = "^[[:alnum:].-]+@[[:alnum:].-]+$"
str_match(emails, regex)
?regex
getwd()
load(cdc.Rdata)
setwd("~/")
load(cdc.Rdata)
setwd("C:\Users\david")
setwd("C:/Users/david")
load(cdc.Rdata)
load("cdc.Rdata")
head(cdc)
class(cdc)
head(cdc)
tail(cdc)
names(cdc)
str(cdc)
mean(cdc$weight)
var(cdc$weight)
table(cdc$smoke100)
table(cdc$smoke100) / nrows(smoke100)
table(cdc$smoke100) / nrow(smoke100)
table(cdc$smoke100) / nrow(cdc$smoke100)
table(cdc$smoke100) / len(cdc$smoke100)
table(cdc$smoke100) / length(cdc$smoke100)
barplot(table(cdc$smoke100))
gender_smokers = table(cdc$gender, cdc$smoke100)
gender_smokers
# Plot the mosaicplot:
mosaicplot(gender_smokers)
head(cdc)
table(cdc$genhlth)
boxplot(cdc$weight)
boxplot(cdc$weight)
?boxplot
boxplot(cdc$height ~ cdc$gender)
bmi = (cdc$weight/cdc$height^2) * 703
# Draw the boxplot:
boxplot(bmi ~ cdc$genhlth)
hist(cdc$age)
hist(cdc$gender)
hist(cdc$weight)
hist(cdc$weight, breaks=50)
plot(cdc$weight, cdc$wtdesire)
load("kobe.Rdata")
head(kobe)
tail(kobe)
kobe_streak = calc_streak(kobe$basket)
barplot(table(kobe_streak))
?calc_streak
??calc_streak
calc_streak
get_streak = function(x){
y = rep(0,length(x))
y[x == "H"] = 1
y = c(0, y, 0)
wz = which(y == 0)
streak = diff(wz) - 1
return(streak)
}
cdc
kobe_streak = calc_streak(kobe$basket)
# Draw a barplot of the result:
barplot(table(kobe_streak))
kobe_streak = get_streak(kobe$basket)
# Draw a barplot of the result:
barplot(table(kobe_streak))
outcomes = c("heads", "tails")
sample(outcomes, size = 1, replace = TRUE)
coins = c("heads", "tails")
sample(coins, size = 100, replace = TRUE)
coins = c("heads", "tails")
fair_coin = sample(coins, size = 100, replace = TRUE)
table(fair_coin)
unfair_coin = sample(outcomes, size = 100, replace = TRUE, prob = c(0.3,
0.7))
unfair_coin = sample(outcomes, size = 100, replace = TRUE, prob = c(0.3,0.7))
table(unfair_coin)
kobe_streak = calc_streak(kobe$basket)
sim_streak = calc_streak(sim_basket)
summary(kobe_streak)
summary(sim_streak)
kobe_table = table(kobe_streak)
sim_table = table(sim_streak)
barplot(kobe_table)
barplot(sim_table)a
outcomes = c("H", "M")
sim_basket = sample(outcomes, size = 133, replace = TRUE, prob = c(0.45, 0.55))
table(sim_basket)
kobe_table = table(kobe_streak)
sim_table = table(sim_streak)
barplot(kobe_table)
barplot(sim_table)
kobe_streak = get_streak(kobe$basket)
sim_streak = get_streak(sim_basket)
kobe_streak = calc_streak(kobe$basket)
sim_streak = calc_streak(sim_basket)
summary(kobe_streak)
summary(sim_streak)
kobe_table = table(kobe_streak)
sim_table = table(sim_streak)
barplot(kobe_table)
barplot(sim_table)
load("ames.Rdata")
head(ames)
head(ames$area)
head(ames$Area)
area = ames$Gr.Liv.Area
hist(area)
head(area)
sample_means_small = rep(NA, 100)
# Run your for loop:
for (i in 1:100) {
samp = sample(area, 50)
sample_means_small[i] = mean(samp)
}
# Print the result:
sample_means_small
sample_means10 = rep(NA, 5000)
sample_means50 = rep(NA, 5000)
sample_means100 = rep(NA, 5000)
for (i in 1:5000) {
samp = sample(area, 10)
sample_means10[i] = mean(samp)
samp = sample(area, 50)
sample_means50[i] = mean(samp)
samp = sample(area, 100)
sample_means100[i] = mean(samp)
}
head(sample_means10)
head(sample_means50)  # was already loaded
head(sample_means100)
par(mfrow = c(3, 1))
# Define the limits for the x-axis:
xlimits = range(sample_means10)
# Draw the histograms:
hist(sample_means10, breaks = 20, xlim = xlimits)
hist(sample_means50, breaks = 20, xlim = xlimits)
hist(sample_means100, breaks = 20, xlim = xlimits)
population = ames$Gr.Liv.Area
samp = sample(population, 60)
sample_mean = mean(samp)
hist(samp)
population = ames$Gr.Liv.Area
samp = sample(population, 60)
sample_mean = mean(samp)
hist(samp)
population = ames$Gr.Liv.Area
samp = sample(population, 60)
sample_mean = mean(samp)
hist(samp)
population = ames$Gr.Liv.Area
samp = sample(population, 50)
sample_mean = mean(samp)
hist(samp)
sde = sd(samp)/sqrt(50)
lower = sample_mean - 1.96 * se
upper = sample_mean + 1.96 * se
lower
upper
sde = sd(samp)/sqrt(50)
lower = sample_mean - 1.96 * sde
upper = sample_mean + 1.96 * sde
lower
upper
sample_mean
str(ames)
for (i in 1:50) {
samp = sample(population, n)
samp_mean[i] = mean(samp)
samp_sd[i] = sd(samp)
}
lower = samp_mean - 1.96 * (samp_sd/sqrt(n))
upper = samp_mean + 1.96 * (samp_sd/sqrt(n))
pop_mean = mean(population)
plot_ci(lower, upper, pop_mean)
samp_mean = rep(NA, 50)
samp_sd = rep(NA, 50)
n = 60
for (i in 1:50) {
samp = sample(population, n)
samp_mean[i] = mean(samp)
samp_sd[i] = sd(samp)
}
lower = samp_mean - 1.96 * (samp_sd/sqrt(n))
upper = samp_mean + 1.96 * (samp_sd/sqrt(n))
pop_mean = mean(population)
plot_ci(lower, upper, pop_mean)
?plot_ci
??plot_ci
dnorm(0)
curve(dnorm,-3,3)
curve(dnorm,-3,3)
?dnorm
dnorm(1000)
dnorm(seq(-3,3, 0,1))
dnorm(seq(-3,3,0.1))
sum(dnorm(seq(-3,3,0.1)))
sum(dnorm(seq(-3,3,1)))
curve(dnorm,-3,3)
curve(pnorm(x), -3,3)
qt(0.975,df=60-1)
qt(0.95,df=60-1)
qt(0.95,df=50-1)
qnorm(0.5)
qnorm(0.95)
qnorm(0)
qnorm(0.975)
qnorm(0.025)
pnorm(1.96)
qnorm(0.9955)
qnorm(0.995)
stem(cdc$weight)
library(ggplot2)
qplot(cdc$weight, binwidth=2)
head(mtcars)
head(cdc)
cov(cdc[c("height", "weight"),])
cdc[c("height", "weight"),]
cdc[,c("height", "weight")]
cov(cdc[,c("height", "weight")])
head(cdc)
cov(cdc[,c("age","height", "weight")])
library(reshape2)
qplot(x=Var1, y=Var2, data=melt(cor(mtcars[1:3])), fill=value, geom="tile")
head(cdc)
boxplot(mtcars$mpg, mtcars$mpg[mtcars$am==0], ylab = "mpg", names=c("overall","automobile"))
abline(h=mean(mtcars$mpg),lwd=2, col="red")
abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col="blue")
boxplot(mtcars$mpg~mtcars$am,ylab='mpg',names=c('automatic','manual'))
abline(h=mean(mtcars$mpg[mtcars$am==0]),lwd=2, col="blue")
abline(h=mean(mtcars$mpg[mtcars$am==1]),lwd=2, col="red")
load("mlb11.Rdata")
head (mlb11)
correlation = cor(mlb11$runs, mlb11$at_bats)
correlation
plot(mlb11$runs, mlb11$at_bats)
plot(mlb11$at_bats, mlb11$runs)
m1 = lm(runs ~ at_bats, data = mlb11)
m1
plot(mlb11$runs ~ mlb11$at_bats)
m1 = lm(runs ~ at_bats, data = mlb11)
abline(m1)
ftable = table(mtcars$am, mtcars$gear)
mosaicplot(ftable, main="Number of Forward Gears Within Automatic and Manual Cars", color = TRUE)
boxplot(mtcars$mpg~factor(mtcars$gear),xlab='gear',ylab='mpg')
par(mfrow=c(1,2))
boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==0),xlab='gear', ylab = "mpg",main='automatic')
boxplot(mtcars$mpg~mtcars$gear,subset=(mtcars$am==1),xlab='gear', ylab = "mpg", main='manual')
boxplot(mtcars$mpg~factor(mtcars$gear)* factor(mtcars$am),xlab='gear * transmission', ylab = "mpg",main='Boxplot of mpg by gear * transmission')
boxplot(mtcars$mpg~factor(mtcars$gear)* factor(mtcars$am),xlab='gear * transmission', ylab = "mpg",main='Boxplot of mpg by gear * transmission')
library(rJava)
library(rJava)
library(rJava)
install.packaes("XML")
install.packages("XML")
library(XML)
library(XML)
fileurl = "http://data.ntpc.gov.tw/NTPC/od/data/api/IMC14?$format=xml&$top=3"
doc = xmlTreeParse(fileurl)
doc
install.packages("jsonlite")
library(jsonlite)
install.packages('httr')
jsondata = fromJSON("https://api.github.com/users/ywchiu/repos")
jsondata
names(jsondata)
install.packages("httr")
con = url("http://travel.rakuten.com/hotel/Japan-Hokkaido-Noboribetsu-Noboribetsu_Onsen_Noboribetsu_Grand_Hotel/39175/")
htmlcode = readLines(con)
close(con)
htmlcode
library(RJDBC)
install.packages("RJDBC")
```
```
df1 = data.frame(id = 1:3, x= rep(1,3))
df2 = data.frame(id = 1:3, y= rnorm(3))
arrange(join(df1,df2), id)
library(plyr)
df1 = data.frame(id = 1:3, x= rep(1,3))
df2 = data.frame(id = 1:3, y= rnorm(3))
arrange(join(df1,df2), id)
library(rJava)
load("cdc.Rdata")
install.packages("e1071")
library(e1071)
pairs(iris[1:4],main="Iris Data (red=setosa,green=versicolor,blue=virginica)", pch=21, bg=c("red","green3","blue")[unclass(iris$Species)])
classifier<-naiveBayes(iris[,1:4], iris[,5])
table(predict(classifier, iris[,-5]), iris[,5])
classifier<-svm(iris[,1:4], iris[,5])
table(predict(classifier, iris[,-5]), iris[,5])
prediction = predict(classifier, iris[,1:4])
---
library(e1071)
install.packages("sos")
?e1071
??e1071
library(e1071)
head(iris)
classifier<-naiveBayes(iris[,1:4], iris[,5])
summary(classfier)
summary(classifier)
table(predict(classifier, iris[,-5]), iris[,5])
classifier<-svm(iris[,1:4], iris[,5])
table(predict(classifier, iris[,-5]), iris[,5])
prediction = predict(classifier, iris[,1:4])
tapply(mtcars$mpg, c(mtcars$gear, mtcars$am), mean)
tapply(mtcars$mpg, c(mtcars$gear, mtcars$am), mean)
tapply(mtcars$mpg, list(mtcars$gear, mtcars$am), mean)
# load the mlbench package which has the BreastCancer data set
require(mlbench)
# if you don't have any required package, use the install.packages() command
# load the data set
data(BreastCancer)
# some algorithms don't like missing values, so remove rows with missing values
BreastCancer <- na.omit(BreastCancer)
# remove the unique identifier, which is useless and would confuse the machine learning algorithms
BreastCancer$Id <- NULL
# partition the data set for 80% training and 20% evaluation (adapted from ?randomForest)
set.seed(2)
ind <- sample(2, nrow(BreastCancer), replace = TRUE, prob=c(0.8, 0.2))
# create model using recursive partitioning on the training data set
require(rpart)
x.rp <- rpart(Class ~ ., data=BreastCancer[ind == 1,])
# predict classes for the evaluation data set
x.rp.pred <- predict(x.rp, type="class", newdata=BreastCancer[ind == 2,])
# score the evaluation data set (extract the probabilities)
x.rp.prob <- predict(x.rp, type="prob", newdata=BreastCancer[ind == 2,])
plot(x.rp, main="Decision tree created using rpart")
x.svm <- svm(Class~., data = BreastCancer[ind == 1,])
library(e1071)
x.svm <- svm(Class~., data = BreastCancer[ind == 1,])
require(ROCR)
# create an ROCR prediction object from rpart() probabilities
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
require(ROCR)
install.packages("ROCR")
require(ROCR)
# create an ROCR prediction object from rpart() probabilities
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
# prepare an ROCR performance object for ROC curve (tpr=true positive rate, fpr=false positive rate)
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
# plot it
plot(x.rp.perf, col=2, main="ROC curves comparing classification performance of five machine learning models")
install.packages("car")
library(car)
data(Quartet)
str(Quartet)
plot(Quartet$x, Quartet$y1)
lmfit = lm(Quartet$y1~Quartet$x)
abline(lmfit, col="red")
plot(Quartet$x, Quartet$y1)
lmfit2 = lsfit(Quartet$x,Quartet$y1)
abline(lmfit2, col="red")
plot(Quartet$x, Quartet$y2)
lmfit = lm(Quartet$y2~poly(Quartet$x,2))
lines(sort(Quartet$x), lmfit$fit[order(Quartet$x)], col = "red")
plot(Quartet$x, Quartet$y3)
lmfit = rlm(Quartet$y3~Quartet$x)
abline(lmfit, col="red")
plot(Quartet$x, Quartet$y3)
lmfit = rlm(Quartet$y3~Quartet$x)
abline(lmfit, col="red")
require(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer$Id <- NULL
set.seed(2)
ind <- sample(2, nrow(BreastCancer), replace = TRUE, prob=c(0.8, 0.2))
x.rp.prob.rocr <- prediction(x.rp.prob[,2], BreastCancer[ind == 2,'Class'])
x.rp.perf <- performance(x.rp.prob.rocr, "tpr","fpr")
setwd("~/rbasic/course4")
dataset <- read.csv('eco_index.csv',head=TRUE, sep=',', row.names=1)
pc.cr <- princomp(dataset, cor = TRUE)
plot(pc.cr)
str(Quartet)
str(Quartet)
data(Quartet)
str(Quartet)
dataset <- read.csv('eco_index.csv',head=TRUE, sep=',', row.names=1)
pc.cr <- princomp(dataset, cor = TRUE)
plot(pc.cr)
getwd()
